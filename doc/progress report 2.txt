                                                         G_SUITE METRICS

Based on the complexity of the G-suite metrics data set, all our team members have divided the g-suite metrics
(Drive, Gmail, Meet, Calendar, Accounts) and each of us stated working on them.

- Google Drive:(Lavanya Goluguri)

I have separated the drive realted data from the original gsuite metrics, and created a new data frame that is fexible to query on parameters.
cleaned that data, dropped the rows that has all nan values, replaced the remaining nan values with the mean of the columns.
As per the suggestions from the mentor I focused more on the 1day active users and 30 day active users.
Also google forms created and edited, google documents created and edited. 
As those point to how much content is being created, and how much is being actually collaborated/updated after creation.

R1 : Coming to statistics part of the drive data the size of the data is now 831 rows X 144 columns, 
the data is collected from 03/2017 to 08/2019. 
I have focused on 1day_active_users, 30day_active_users and google_forms_created, google_forms_edited. 
I did the basic statistics on these parameters like mean, variance, distributions modelling, Maximum likelihood , 
kernel density estimators on the distributions, point estimates, correlation and covariance among parameters and 
Hypothesis testing on the above stated parameters to see if the null hypothesis is considered or 
the alternate hypothesis is considered.
https://github.com/UNCG-CSE/G_Suite_Metrics/tree/Gsuite_lavanyagoluguri

R2: I have spent a considerable amount of time on these tasks.

R3: The Mean of the 1day_active users, 30day_active_users is 3888 and 15955.
In the Inter quartile range there are around 3300 to 4300 1day and 30day active users.
Both the 1day_active_users and 30day_active_users data is discrete so that distribution fit for both is poisson distribution. 
The estimators I used is the kernel density estimator to check my distribution modelling. 
In the point estimates , 
I have taken samples from the 1day and 30 day active users and used the Central limit theorem to plot the mean of the samples,
which is a normal distribution.
I checked the covariance and correlation of the two parameters, it is 0.45, means they are not highly correlated.
I have calculated the confidence intervals, t- critial and z- critical values.
I formed the hypothesis tha the mean of the 1day active users is significantly different from the mean of 30 day active users,
I did the one sample ttest, two sample ttest independent and the relative testing. 
The p value is 0.32, which is >0.05 means we fail to reject the null hypothesis. 

Google Meet:(Anusha Vanama)

Our mentor suggested me to mainly focus on below 6 metrics under Google Meet.

google.meet:total_call_minutes 
google.meet:num_30day_active_users
google.meet:num_meetings
google.meet:num_calls
google.meet:average_meeting_minutes
google.meet:total_meeting_minutes

Currently, I had completed Basic Data Exploration on google.meet:total_call_minutes. 
I am going to perform metrics for remaining metrics as well following the same procedure.

R1 Work done towards the tasks with links to notebooks

Task 1: Extraction of Google Meet data and statistical evaluation
Extracted Google Meet related metrics from the G suite Metrics data set and stored in a new data frame. 
Performed Initial analysis on Google Meet data. 
Task 2: Statistical evaluation of Total Call Minutes metric of Google Meet
Performed initial analysis on Google Meet dataset. Selected total call minutes metric from the top 6 Google Meet metrics as suggested by our mentor
and performed further analysis. Calculated Mean, Mode, Variance, Standard deviation, Interquartile (IQR) range and all basic statistics for total call minutes metric.
Task 3: Distribution Modeling
Plotted Total Call Minutes data using Histograms to observe what sort of distribution will fit my data.
Kernel Density Estimation is used to find probability density function (PDF) for Total Call Minutes data.
Task 4: Finding Correlation and Co-variance within the data
Task 5: Point Estimates
Task 6: Hypothesis testing

Below is the github link for all the above tasks
https://github.com/UNCG-CSE/G_Suite_Metrics/tree/master/src/Anusha

R2 Number of hours spent on each task.
Needs to be updated

R3 Description of the results obtained from the tasks. (4-5 lines for each task)
Results for Task 1: Extraction of Google Meet data and statistical evaluation
There are 55 unique metric names, 29434 observations under Google Meet recorded from January 14th, 2018 to August 17th, 2019.
There are 17731 observations in 2018 and 11703 in 2019.
Some of the Metric Values of Google Meet includes Number of users, Number of Minutes, Number of Meetings, Number of Calls, 
Usage of Chromebox and Usage of Chromebase. 
We have same metric names in both years and there are no new metrics added in 2019.


Results for Task 2: Statistical evaluation of Total Call Minutes metric of Google Meet
There are 543 observations under Total Call Minutes metric of Google Meet. There are 328 observations in 2018 and 215 in 2019.
The Metric Value here is Number of total call minutes which are extracted on daily basis. Metric value is 0 for 155 days.
Maximum number of total_call_minutes is 7623 minutes recorded on 2019-07-01.
Median of metric values is 782 and Mean value is 1152.29 which is far away from median as we have extreme values for total call minutes for few days. 
Eg: There are 7623 minutes on 2019-07-01. Interquartile (IQR) range value is 1861 minutes.
Variance and Standard Deviation are not the right measures of spread as the data is having extreme values.
Median absolute deviation is the right measure of spread for TotalCallMinutes metric which is around 1159.4 minutes.
