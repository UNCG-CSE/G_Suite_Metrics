
                                                          G_SUITE METRICS
                                                          
Google Drive:(Lavanya Goluguri):
Tasks:
My main task for this project is to work on the drive data, find its anomalies, patterns, distributions and predictions.
In the work of progress towards this task, I have selected the important metrics in the drive data and applied time series analysi on
the data. To discuss about it in detail my Machine learning analysis is as stated below.
So, the metrics that are mainly focused on in the drive data are:
1day_active_users
30day_active_users
Google_forms_created
Google_forms_edited
Google_documents_created
Google_documents_edited
Google_presentations_created
Google_presentations_edited
Google_Spreadsheets_created
Google_spreadsheets_edited
Google_drawings_created
Google_drawings_edited
I considered these as those point to how much content is being created, and how much is being actually collaborated/updated after
creation.
Question asked: The question that I mainly posed on my data, is can I predict the data of 2020 based on my current available data and
how accurate would be the predictions.
Methods Used: The methods used in answering this question is Time series analysis using fb prophet.
What was done to solve the question: As the data is time series data, I did the time series analysis to predict the future values.
Functions from fb probphet are used to predict and forecast the data of 2020 based on the data of 2 years that is provided as input to the algorithm. 
Then the predictions are plotted with cross validations, there are few attributes that predicted with good accuracies and few others where predictions were not as expected.
I mainly considered mse(Mean squared error), mape(Mean absolute percentage error) as measures for error and accuracies.
Outcomes:
Their Implications: I find the prediction were following the similar trends as the input data in many cases, there are clear variations that can be identified in the beggining of the semester, semester break, end of the semesters.
The predictions are more accurate in the initial days of the forecast like the first 50 days than compared to the end of the days of the prediction.
I was also able to see the trends in the data for some attributes like what is the hourly usage, weekly usage, daily usage which can help in understanding how the google drive is being used by members of UNCG.


- Google Meet:(Anusha Vanama)
Question asked
Prediction of future metric value based on the current data set values for below metrics under Google Meet.
google.meet:total_call_minutes 
google.meet:num_30day_active_users
google.meet:num_meetings
google.meet:num_calls
google.meet:average_meeting_minutes
google.meet:total_meeting_minutes
Why was the question asked?
Our mentor is interested in finding the unexpected spikes, drops, trend changes and level shifts
He is also interested in comparison among devices(iOS/android/jam board).

Describe the method.
Time series forecasting is a technique for the prediction of events through a sequence of time.
The techniques predict future events by analyzing the trends of the past, on the assumption that future trends will hold similar to historical trends.
Prophet is a procedure for forecasting time series data based on an additive model where non-linear trends are fit with yearly, weekly, and daily seasonality, plus holiday effects.
Prophet is open source software released by Facebook's Core Data Science team. Facebook prophet is used to perform time series analysis on google meet metrics. 

Linear regression is a linear approach to modeling the relationship between a scalar response (or dependent variable) and 
one or more explanatory variables (or independent variables). Total_call_minutes is considered as dependent variable and Total_call_minutes_iOS, 
Total_call_minutes_android, Total_call_minutes_jamboard are considered as independent variables.

What was done to solve for the question?
The input to Prophet is always a dataframe with two columns: ds and y. The ds (datestamp) column and the y column represents the values of a metric we wish to forecast.
We fit the model by instantiating a new Prophet object. Predictions are made for the future period of 365 days(1 Year). 
The predict method is used which will assign each row in future a predicted value. Plotted the forecast using Prophet.plot method.
Prophet.plot_components method is used to see the trends and weekly seasonality of the time series. 
Describe outcomes.

What were the outcomes and What are their implications?
Cross validations are done to assess prediction performance on a horizon of 70 days, starting with 210 days of training data in the first cutoff and then making predictions every 15 days.
Performance metrics is used to compute some useful statistics of the prediction performance. The statistics computed are mean squared error (MSE), 
root mean squared error (RMSE), mean absolute error (MAE), mean absolute percent error (MAPE), and coverage of the yhat_lower and yhat_upper estimates.

The mean absolute percent error (MAPE) expresses accuracy as a percentage of the error. Because the MAPE is a percentage, 
it can be easier to understand than the other accuracy measure statistics.
During my Initial analysis, MAPE value is not displayed as most of the actual metric values in Google Meet data are zero. 
Because MAPE divides the absolute error by the actual data, values close to 0 can greatly inflate the MAPE.
I have observed that the metric values are zero from Jan 2018 to May 2018 for most of the Google Meet metrics. My mentor suggested me that the reason is 
likely that metric didn't exist then, or google discontinued temporarily. He suggested me to perform time series analysis by ignoring them.
The predicted trends for the nex year is similar to the trends in the previous years. Google meet usage is very less at the beginning of the semester and the usage increases slowly and at the end it is high. Again, after the semester ends usage is decreasing. The same pattern is followed in 2019 and the predicted pattern is also the same for 2020.
Even though after removing them, MAPE value is greater than 20 percent. Here,  MAPE does not give good results as we have a low volume of data. 
In Google Meet metrics, all the actual values are very small.

Simple Linear Regression and Multiple Linear Regression:
The most common way to evaluate the overall fit of a linear model is by the R-squared value.
Initially, I have performed simple linear regression is used to find relationship between total_call_minutes and total_call_minutes_ios.
R-squared value for this model is around 0.25507273021955723.
Using Multiple Linear Regression, I found out that the total_call_minutes_ios, total_call_minutes_android and total_call_minutes_jamboard are positively associated with total_call_minutes. 
This model has a higher R-squared (0.299) than the previous model(0.25507273021955723), which means that this model provides a better fit to the data than a model that only includes total_call_minutes_ios.


- Google Gmail:(Henry Reichard):
Tasks:
My main task for this project is to work on the gmail data, find its anomalies, patterns, distributions and predictions.
In the work of progress towards this task, our mentor have selected the important metrics in the gmail data and applied time series analysi on the data. I also picked additional metrics that might be interesting for this project. 
So, the metrics that are mainly focused on in the drive data are:
Mentor picked attributes:
num_emails_received
num_emails_sent
num_inbound_rejected_emails
num_inbound_spam_emails
num_inbound_non_spam_emails
Additional attributes:
1day_active_users
num_emails_exchanged
inbound_delivered_emails
outbound_rejected_emails

Question asked:
The question that I mainly posed on my data, is can I predict the data of 2020 based on my current available data and
how accurate would be the predictions and if I can fill 0s or missing days in my dataset.

Methods Used: 
The methods used in answering this question is Time series analysis using fb prophet.

What was done to solve the question: 
Written a function that sent the time column and the attribute to the fb prophet function. The fb prophet function returns a crossvalidation head and tail, and a plot of the prediction and the datapoints. Additionally written a function to send the data and return a MAPE graph to visualize the error. Some predictions gave negative values and after talking with the mentor and with Dr.Mohanty I went ahead and cap the negative values with 0. I filled 0s and missing days in the dataset with the mentor picked attributes with predicted values

Outcomes:
For emails_Received, emails_sent, 1day_active_users,email_exchange got a really good prediction (MAPE score close to 0) for 365 days out into the future. For inbound_non_spam_emails it has a pretty decent MAPE score of around 16% for 40 days into the future prediction and around 44% at the end of the year prediction. It can give a decent prediction around 50 days in advance, which isnt too bad. For inbound_delivered_emails it gives a decent prediction all around, around 13% around 40 days into the future and 33% at the end of the prediction. For inbound_rejected_emails and inbound_spam_emails they have MAPE score of around 41% and 23% at 40 days into the future and 305% and 84% at 365 days. Inbound_rejected_emails have some anomolies in the data because there is strong spikes around the first half of the data and a period of growth and regression before it drops off around midpoint of 2017. After the drop off the growth is stagnated and no apparent spikes. This could explain the poor MAPE score because the data is vastly different in the first half and the second half. The MAPE score has improved once the time series analysis was performed on the second half of the data only. Inbound_spam_emails is preculiar as well because there is a massive drop off around the midpoint of 2018 and the growth is sluggish afterwards. This could explain the poor MAPE score near the end of the prediction as well. The explanation of these drop off will be explained below.

Their Implications:
The decent predictions for emails_Received, emails_sent, 1day_active_users, email_exchange, inbound_non_spam_emails, inbound_delivered_emails will give the ITS department a firm understanding what is happening with Gmail throughout the year and allow the ITS department to prepare in advance to seasonal and overall trends in Gmail. The big question is why these services are not growing proportional to the growth of UNCG? After discussing with the mentor possible conclusions has been made why this is happening. These possible conclusions are the following:
 1) Students don't send emails as much as they used to 5 years ago. 
 2) People are using chat more than email now. 
 3) Google is doing a better job of blocking spam from being received in the first place.
 4) Active users however are expected to see similar growth in relation to the overall population. It's possible students/users aren't          using their accounts as much as they used to. 
 5) Students who graduated or Faculty leaving UNCG might not be the same "quality" users as users coming into UNCG, as in a new users are     not as in grained as older users and will not use it that much in the beginning. With a influx of new users over the years it could     explain why the growth is not proportional. 
The anomolies found in inbound_rejected_emails and inbound_spam_emails can be explained by multiple of reasons. Before Nick (The mentor) joined the ITS Department, the ITS department used to be only reactive too attacks or spam. Over the years the ITS department took the "best defense is the best offense" approach by being more proactive. Additionally it is likely Google is doing a better job of handling rejections than they were before. IE : better at spam and phishing prevention. These reasons explains why there is a huge drop off in these attributes. The implication here is that there is progress being made to limit spam or hazardous emails and that is a good thing. 

- Dashboard Development and Calendar Analysis (Jackie Cuong):

Tasks: 
My main task was to develop a dashboard to help visualize the data for our mentor and for later use by the mentor, I also had a small task in performing time series analysis on the google calendar data.

Question asked: 
How can I visualize data to demonstrate changes in the data over time?

Methods used: 
Used google data studio and its graph generation features to create line graphs to demonstrate changes in the data over time and in the future, and used FB Prophet to make predictions on Google Calendar data

Results and Outcomes:  
Dashboard is complete and filled with line graphs with data containing both data gathered from G-Suites and data predicted using FB Prophet, along with data filtering and date filtering for extended analysis.  For the calendar analysis the prediction made displayed a graph that had a very slight increase in number of users towards the end of the graph, this implies that in 2020 the amount of users using google calendar will increase.

-Google Account and Dashboard Development (Hieu Vo)
My main task was to create visualizations to demonstate the change over time of some attributes. I also performed machine learning with google account data using simple linear regression and fb prophet to predict and forecast the future of specific atttribute. I also finished my pandas_profiling and correlation matrix.

Main attributes:
Google drive mb
Google gmail mb
Google gplus mb
Google 1, 7 and 30 day active user
Google total quota mb

Progress:
Using  fbprophet for forecasting time series data.
Using linear-regression machine learning to predict the amount of data use for each google service based on amount of users.
Visualization of data used from google Gmail, drive and Gplus

Results:
Predict the increasing in data usage in the future.
Predict data usage base on number of users.
Predict active users in the future.
Visualizations help to tell the increasing or decreasing of data usage.

